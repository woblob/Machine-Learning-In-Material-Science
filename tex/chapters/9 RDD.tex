\phantomsection
\setstretch{1.5}
\justify
\fontsize{14}{16}\selectfont
\setlength{\parindent}{0pt}
\section*{5. Regresor drzewa decyzyjnego \cite{alma991000280759708832}}
\label{sec:machine_learning_overview}
\addcontentsline{toc}{section}{5. Regresor drzewa decyzyjnego}
\fontsize{12}{14}\selectfont
\vspace{-1.0em}

\hspace{1.5cm} Regresor drzewa decyzyjnego to nieliniowy model regresji. Wykorzystuje strukturę przypominającą drzewo do tworzenia prognoz na podstawie wartości cech wejściowych. Jest częścią szerszej rodziny algorytmów drzew decyzyjnych, które mogą być używane zarówno do zadań klasyfikacji, jak i regresji. Ten model jest zdolny do wychwytywania złożonych wzorców w danych, a jednocześnie wrażliwy na nadmierne dopasowanie bez odpowiedniej regularyzacji.

\phantomsection
\setstretch{1.5}
\section*{Zasada działania}
\vspace{-1.0em}
\label{sec:what_is_ml}

\hspace{1.5cm} Model składa się z węzłów i gałęzi. Każdy węzeł wewnętrzny reprezentuje cechę (lub atrybut), każda gałąź reprezentuje regułę decyzyjną, a każdy węzeł liścia reprezentuje przewidywany wynik (wartość zmiennej docelowej). Ogólna budowa przypomina strukturę drzewa.

Regresor drzewa decyzyjnego dzieli dane w każdym węźle na podstawie określonych kryteriów, takich jak minimalizacja średniego błędu kwadratowego (MSE) lub średniego błędu bezwzględnego (MAE). Celem jest utworzenie jednorodnych podzbiorów danych, które są jak najbardziej podobne pod względem zmiennej docelowej.

Proces podziału jest kontynuowany rekurencyjnie, aż do spełnienia kryterium zatrzymania. Może to być osiągnięcie maksymalnej głębokości, posiadanie minimalnej liczby próbek w węźle lub osiągnięcie zadowalającego poziomu czystości w węzłach liściowych.


\phantomsection
\setstretch{1.5}
\section*{CART dla regresora drzewa decyzyjnego}
\vspace{-1.0em}
\label{sec:ml_challenges}


\hspace{1.5cm} CART (Drzewa klasyfikacji i regresji) to algorytm używany do tworzenia drzew decyzyjnych zarówno dla zadań klasyfikacji, jak i regresji. W przypadku regresji, CART konstruuje drzewo, które przewiduje ciągłe wyniki, dzieląc dane na podzbiory na podstawie wartości cech.

\phantomsection
\setstretch{1.5}
\section*{Jak działa CART?}
\vspace{-1.0em}
\label{sec:ml_challenges}

\begin{itemize}

\item {\textbf{\textit{Partycjonowanie rekurencyjne}}}: Algorytm CART rekurencyjnie dzieli zbiór danych na dwa lub więcej jednorodnych zestawów na podstawie wartości cech wejściowych. Każdy podział jest określany przez znalezienie cechy i progu, które minimalizują błąd prognozy w wynikowych podzbiorach.
\item {\textbf{\textit{Kryteria podziału}}}: W przypadku drzew regresyjnych CART używa średniego błędu kwadratowego (MSE) jako kryterium podziału. Algorytm ocenia wszystkie możliwe podziały i wybiera ten, który skutkuje największą redukcją MSE.
\item {\textbf{\textit{Węzły liściowe}}}: Gdy drzewo osiągnie kryterium zatrzymania (takie jak maksymalna głębokość lub minimalna liczba próbek na liść), każdy węzeł liściowy reprezentuje przewidywaną wartość, która jest zazwyczaj średnią wartości docelowych w tym węźle.
\end{itemize}

\phantomsection
\setstretch{1.5}
\section*{Funkcja kosztu}
\vspace{-1.0em}
\label{sec:ml_challenges}

\hspace{1.5cm} Funkcja kosztu używana w CART do regresji opiera się na minimalizacji średniego błędu kwadratowego (MSE). 
Podczas każdego podziału CART oblicza MSE dla potencjalnych podziałów i wybiera ten, który minimalizuje ten błąd we wszystkich powstałych węzłach podrzędnych.

\phantomsection
\setstretch{1.5}
\section*{Zalety }
\vspace{-1.0em}
\label{sec:ml_challenges}

\hspace{1.5cm} Drzewa decyzyjne oraz algorytm CART są łatwe do wizualizacji i interpretacji, co czyni je prostymi do zrozumienia sposobu podejmowania decyzji. Mogą uchwycić złożone relacje między cechami a zmienną docelową bez konieczności przyjmowania założeń liniowych. Drzewa decyzyjne mogą również zapewnić wgląd w znaczenie cech, pomagając zidentyfikować zmienne, które mają największy wpływ na przewidywania.
Dodatkowo, CART może obsługiwać zarówno dane liczbowe, jak i kategoryczne, co czyni go wszechstronnym narzędziem w różnych zastosowaniach.


\phantomsection
\setstretch{1.5}
\section*{Ograniczenia }
\vspace{-1.0em}
\label{sec:ml_challenges}

\hspace{1.5cm} Drzewa decyzyjne są podatne na nadmierne dopasowanie, szczególnie jeśli pozwoli się im urosnąć zbyt głęboko, co prowadzi do słabej generalizacji niewidzianych danych. Dodatkowo niewielkie zmiany w danych mogą skutkować znacząco różnymi strukturami drzew, co czyni je wrażliwymi na szum w zestawie danych.

\phantomsection
\setstretch{1.5}
\section*{Techniki regularyzacji \cite{url_DecisionTreeRegressor}}
\vspace{-1.0em}
\label{sec:ml_challenges}

\hspace{1.5cm} Aby złagodzić nadmierne dopasowanie i poprawić stabilność modeli drzew decyzyjnych, można dostrajać hiperparametry takie jak maksymalna głębokość, minimalna liczba próbek wymaganych do podziału węzła wewnętrznego oraz minimalna liczba próbek w węźle liścia.



\phantomsection
\setstretch{1.5}
\section*{Zastosowania}
\vspace{-0.5em}
\label{sec:ml_challenges}

Regresory drzewa decyzyjnego oraz algorytm CART są szeroko stosowane w dziedzinach, gdzie łatwość interpretacji i obsługa nieliniowych relacji są niezbędne.

\phantomsection
\setstretch{1.5}
\section*{Użyte parametry dla GridSearchCV \cite{url_DecisionTreeRegressor, url_grid_search}}
\vspace{-1.0em}
\label{sec:ml_challenges}

\begin{itemize}
\setlength\itemsep{-0.5em}
\item max\_depth: ustawia maksymalną głębokość drzewa.
\item min\_samples\_split: określa minimalną liczbę próbek wymaganą do podziału węzła wewnętrznego.
\item min\_samples\_leaf: ustawia minimalną liczbę próbek, które muszą być obecne w węźle liścia.
\item splitter: określa strategię używaną do wybierania podziału w każdym węźle.
\end{itemize}

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}