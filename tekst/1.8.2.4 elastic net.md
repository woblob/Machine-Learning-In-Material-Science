### Regresja Elastic Net

Elastic Net to technika regresji liniowej, która łączy właściwości regresji Lasso (regularyzacja L1) i Ridge'a (regularyzacja L2). Jest ona szczególnie przydatna w przypadku zbiorów danych, które mają wiele skorelowanych cech lub gdy liczba predyktorów przekracza liczbę obserwacji.

#### Wzór ogólny
Funkcję kosztu dla Elastic Net można wyrazić jako:

$$
L = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_{i1} + \ldots + \beta_n x_{in}))^2 + r \lambda_1 \sum_{j=1}^{n} |\beta_j| + \frac{1-r}{2}\lambda_2 \sum_{j=1}^{n} \beta_j^2
$$

Gdzie:
- $ L $ jest całkowitą funkcją kosztu.
- $ y_i $ to rzeczywiste wartości zmiennej zależnej.
- $ x_{ij} $ to zmienne niezależne (cechy).
- $ \beta_j $ to współczynniki modelu.
- $ \lambda_1 $ to parametr regularyzacji dla kary L1 (Lasso).
- $ \lambda_2 $ to parametr regularyzacji dla kary L2 (Ridge).
- $ r $ współczynnik określający proporcję między karą L1 (Lasso) a karą L2 (Ridge) w funkcji kosztu.

Współczynnik $ r $ może przyjmować wartości z przedziału [0, 1]. Gdy $ r $ jest bliskie 0, model Elastic Net jest bardziej podobny do modelu Ridge, a gdy $ r $ jest bliskie 1, bardziej do modelu Lasso.

## Główne cechy 

Regresja Elastic Net łączy w sobie elementy regularyzacji L1 i L2, co pozwala na jednoczesny wybór zmiennych oraz uwzględnienie współliniowości między predyktorami. To podwójne podejście jest szczególnie korzystne w sytuacjach, gdy cechy są silnie skorelowane, co może stanowić problem dla samego modelu Lasso. Składnik L1 promuje rzadkość w modelu, ustawiając niektóre współczynniki na zero, podczas gdy składnik L2 zapewnia stabilność, zmniejszając wartości współczynników skorelowanych predyktorów.

### Zalety 

Jedną z głównych zalet modelu Elastic Net jest jego elastyczność. Dzięki możliwości dostosowywania zarówno parametru regularyzacji $ \lambda_1 $, jak i $ \lambda_2 $, model może być optymalizowany do różnych zestawów danych i wymagań modelowania, co czyni go wszechstronnym narzędziem w wielu problemach regresji. Elastic Net skutecznie radzi sobie z wieloma predyktorami, zwłaszcza w przypadku silnej korelacji między nimi lub gdy liczba predyktorów przewyższa liczbę obserwacji.

### Ograniczenia

Elastic Net ma dwa parametry regularyzacji, co utrudnia dostrajanie modelu. Wymaga starannego dostrajania hiperparametrów, aby uzyskać optymalną wydajność, ale może prowadzić do modeli trudniejszych w interpretacji.

### Zastosowania

Elastic Net znajduje szerokie zastosowanie w dziedzinach, gdzie wybór cech i współliniowość są kluczowe. łącząca zalety regresji Lasso i Ridge, oferująca solidne rozwiązanie do modelowania liniowego w złożonych zbiorach danych z skorelowanymi cechami.
