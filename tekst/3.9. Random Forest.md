### Random Forest Regressor

Random Forest Regressor to metoda uczenia się zespołowego, która łączy wiele drzew decyzyjnych w celu uzyskania dokładniejszych i bardziej solidnych prognoz dla zadań regresji. Jest częścią szerszej rodziny algorytmów Random Forest, które mogą być używane zarówno do klasyfikacji, jak i regresji.

Random Forest Regressor buduje wiele drzew decyzyjnych podczas treningu. Każde drzewo jest trenowane na losowym podzbiorze danych treningowych. Takie podejście wprowadza różnorodność wśród drzew i pomaga zmniejszyć ryzyko nadmiernego dopasowania.

Algorytm wykorzystuje technikę zwaną 'agregacją przykładów wstępnych' (bagging), w której każde drzewo jest trenowane na próbce "bootstrap'owej" (losowe próbkowanie z zastępowaniem)zestawu danych. Oznacza to, że każde drzewo widzi nieco inną wersję danych.

Podczas dzielenia węzłów w każdym drzewie, Random Forest wybiera losowy podzbiór cech zamiast brać pod uwagę wszystkie cechy. To zwiększa różnorodność drzew i pomaga zapobiegać nadmiernemu dopasowaniu.

W przypadku zadań regresji ostateczna prognoza regresora Random Forest jest zazwyczaj średnią prognoz wykonanych przez wszystkie poszczególne drzewa. Ten proces uśredniania pomaga wygładzić błędy i poprawić ogólną dokładność modelu.

#### Zalety
Random Forest posiada mniejszą podatność na nadmierne dopasowanie w porównaniu do pojedynczych drzew decyzyjnych. Zawdzięcza to swojej naturze zespołowej i mechanizmowi uśredniania. 

Model ten potrafi uchwycić złożone relacje między cechami a zmienną docelową bez konieczności przyjmowania założeń liniowych.

Dodatkowo dostarcza wglądu w znaczenie cech, pomagając zidentyfikować zmienne, które mają największy wpływ na prognozy.

#### Ograniczenia
Jest znacznie trudniejszy do zinterpretowania niż pojedyncze drzewa decyzyjne. Zespołowa natura modelu utrudnia zrozumienie, w jaki sposób tworzone są prognozy. 

Szkolenie wielu drzew może być intensywne obliczeniowo, szczególnie w przypadku dużych zestawów danych lub przy użyciu wielu funkcji.

#### Zastosowania
Zastosowanie w pracach naukowych: Algorytm jest stosowany w pracach naukowych, np. do oceny jakości artykułów Wikipedii.

### Kluczowe różnice między Regresorami Random Forest a Drzewem Decyzyjnym

Regresor drzewa decyzyjnego (RDD) opiera się na pojedynczym drzewie decyzyjnym, które tworzy prognozy poprzez rekurencyjne dzielenie danych na podstawie wartości cech. W przeciwieństwie do tego, regresor lasu losowego (RLL) buduje wiele drzew decyzyjnych podczas treningu i łączy ich prognozy, aby wygenerować ostateczny wynik poprzez uśrednienie prognoz ze wszystkich drzew.

RDD jest bardziej podatny na przetrenowanie, szczególnie gdy może rosnąć głęboko bez ograniczeń. Z kolei RLL jest bardziej odporny na nadmierne dopasowanie dzięki uśrednianiu wielu drzew oraz losowości wprowadzanej przez 'bagging' i wybór cech.

Jeśli chodzi o metodę przewidywania, regresor drzewa decyzyjnego tworzy przewidywania wyłącznie na podstawie struktury pojedynczego drzewa, co może prowadzić do dużej wariancji w przewidywaniach. W przeciwieństwie do tego, regresor Random Forest zmniejsza wariancję i poprawia dokładność poprzez uśrednianie wyników wszystkich pojedynczych drzew.

Ze względu na charakter zespołu wielu drzew, RLL jest trudniejszy do zanalizowania niż RDD. 

Złożoność obliczeniowa to kolejny aspekt różniący te modele. Regresor drzewa decyzyjnego jest zazwyczaj szybszy w szkoleniu, ponieważ wymaga zbudowania tylko jednego drzewa. Natomiast regresor lasu losowego wymaga większych zasobów obliczeniowych i czasu na szkolenie ze względu na budowę wielu drzew oraz potrzebę agregacji.

Oba modele mogą dostarczać informacji o ważności cech; jednak metryki ważności cech generowane przez regresor lasu losowego są często uznawane za bardziej wiarygodne dzięki agregacji wyników z wielu drzew.


#### Użyte parametry dla GridSearchCV

- n_estimators: określa liczbę drzew w lesie.
- max_leaf_nodes: ustawia maksymalną liczbę węzłów liściowych w każdym drzewie.
- max_depth: określa maksymalną głębokość każdego drzewa.
- bootstrap: parametr logiczny. Wskazuje czy 'bootstrap'ować' próbki do budowania drzew. Jeśli False, cały zestaw danych jest używany do budowania każdego drzewa.

Bibliografia:
[1] Géron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd ed.). O'Reilly Media.

[2] https://scikit-learn.org/dev/modules/grid_search.html

[3] https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html

[4] Węcel K., Lewoniewski W. Modelling the Quality of Attributes in Wikipedia Infoboxes// Lecture Notes in Business Information Processing: journal. – 2015. – 2 December (vol.228) - P. 308–320. — doi : 10.1007/978-3-19-367262-3_27. 

[5] Lewoniewski W., Węcel K., Abramowicz W. Quality and Importance of Wikipedia Articles in Different LanguagesInformation and Software Technologies. ICIST 2016. Communications in Computer and Information Science: journal. – 2016. 22 September (vol.vol. 639639). - P. 613–624 – doidoi: 10.1007/978-3-19-32624-75-7. 

[6] Warncake-Wang M., Cosley D., Riedl J. Tell me more: An actionable quality model for wikipedia // WikiSym '13 Proceedings of the 9th International Symposium on Open Collaboration: The Journal. — 2013. — doi : 10.1145/2490555.2491063. 
