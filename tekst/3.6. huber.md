### Regresor Hubera

Regresor Hubera łączy zasady najmniejszych kwadratów i funkcje kosztu błędu bezwzględnego. Jest skuteczna w scenariuszach, w których zbiór danych zawiera wartości odstające, ponieważ zmniejsza ich wpływ na przewidywania modelu. 

#### Zasada działania
Funkcja kosztu Hubera jest zdefiniowana następująco $^{[2]}$:

$$
L_\delta( y, \hat{y} ) = \begin{cases}
    ( y - \hat{y} )^2 & \text{for} | y - \hat{y} | \leq \delta \\
    2 \delta  | y - \hat{y} | - \delta^2  & \text{for} | y - \hat{y} | > \delta
\end{cases}
$$

Gdzie:
- $y$ jest wartością rzeczywistą.
- $\hat{y}$ jest wartością przewidywaną.
- $\delta$ jest parametrem progowym, który określa punkt, w którym funkcja kosztu przechodzi z kwadratowej na liniową.

Funkcja kosztu Hubera jest zdefiniowana w taki sposób, że dla reszt (różnic między wartościami rzeczywistymi a przewidywanymi) mniejszych niż parametr progowy $\delta$, koszt zachowuje się jak błąd kwadratowy. To oznacza, że jest bardziej wrażliwy na małe błędy. Natomiast dla reszt większych niż $\delta$ koszt przechodzi na liniową formę. Sprawia to, że model staje się mniej wrażliwy na wartości odstające. 

Wybór parametru $\delta$ w regresorze Hubera jest kluczowy dla wydajności modelu. Mniejsza wartość $\delta$ sprawia, że model staje się bardziej wrażliwy na wartości odstające, co może być korzystne w przypadku danych o niskiej liczbie anomalii, natomiast większa wartość $\delta$ zwiększa odporność modelu na wartości odstające, co czyni go bardziej stabilnym w trudniejszych warunkach.

#### Zalety
Regresor Hubera cechuje się małą wrażliwością na wartości odstające w porównaniu ze zwykłą regresją najmniejszych kwadratów. Dzięki temu jest preferowanym wyborem w przypadku zbiorów danych z obserwacjami anomalnymi. Ponadto, oferuje płynne przejście między kwadratowymi i liniowymi funkcjami kosztów, co zapewnia równowagę między wrażliwością na małe błędy a odpornością na duże błędy.

#### Ograniczenia
Wybór parametru $\delta$ może znacząco wpłynąć na wydajność modelu. Wybór odpowiedniej wartości może wymagać walidacji krzyżowej lub wiedzy o domenie.
Ponadto, regresja Hubera może być bardziej intensywna obliczeniowo niż prostsze modele, szczególnie w przestrzeniach wielowymiarowych. Model ten może nie być tak skuteczny w przypadkach, gdy dane są silnie skorelowane lub gdy istnieją silne nieliniowe relacje między zmiennymi.

#### Zastosowania
Ten model jest często preferowanym wyborem w przypadkach, gdy dane mogą zawierać anomalie.

Podsumowując, regresor Hubera zapewnia solidną alternatywę dla tradycyjnych technik regresji, łącząc zalety zarówno metod najmniejszych kwadratów, jak i metod błędów bezwzględnych, dzięki czemu nadaje się do zestawów danych z wartościami odstającymi, przy jednoczesnym zachowaniu dobrej wydajności predykcyjnej.



#### Użyte parametry dla GridSearchCV

- max_iter: określa maksymalną liczbę iteracji algorytmu optymalizacji.
- epsilon: określa próg klasyfikacji reszt jako wartości odstających. Za niska wartość może prowadzić do niedopasowania, natomiast za wysoka, do przetrenowania.
- alpha: kontroluje siłę regularyzacji stosowaną do modelu.
- fit_intercept: parametr logiczny wskazuje, czy obliczyć przecięcie dla tego modelu. Krytyczne dla danych standaryzowanych. 



Bibliografia:

[1] Huber, Peter J. (1964). "Robust Estimation of a Location Parameter". Annals of Statistics. 53 (1): 73–101. doi:10.1214/aoms/1177703732

[2] Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome (2009). The Elements of Statistical Learning. p. 349. 

[3] https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.HuberRegressor.html

[4] https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html

