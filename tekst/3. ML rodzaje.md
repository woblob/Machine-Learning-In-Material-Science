Uczenie maszynowe (ML) można ogólnie podzielić na dwa główne typy: **klasyfikację** i **regresję**. Obie są podstawowymi technikami stosowanymi w uczeniu nadzorowanym, ale służą różnym celom i są stosowane w różnych kontekstach. Ten przegląd skupi się głównie na regresji, szczegółowo opisując jej cechy, zastosowania i metodologie.

### Klasyfikacja kontra regresja

- **Klasyfikacja**: To zadanie obejmuje przewidywanie wyników kategorycznych. Na przykład model klasyfikacji może przewidywać, czy wiadomość e-mail jest spamem, czy nie (klasyfikacja binarna) lub klasyfikować obrazy do wielu kategorii (klasyfikacja wieloklasowa). Wynik jest dyskretny, reprezentujący etykiety klas.

- **Regresja**: Natomiast regresja dotyczy przewidywania ciągłych wartości liczbowych. Na przykład modele regresji mogą przewidywać ceny domów na podstawie różnych cech, takich jak rozmiar, lokalizacja i liczba sypialni. Wynik jest liczbą rzeczywistą, co czyni ją odpowiednią do zadań, których celem jest oszacowanie ilości.

#### Definicja regresji
Analiza regresji to metoda statystyczna stosowana do modelowania relacji między zmienną zależną (wynikiem) a jedną lub większą liczbą zmiennych niezależnych (predyktorami). Głównym celem regresji jest określenie, w jaki sposób zmiany zmiennych predykcyjnych wpływają na zmienną wynikową.

#### Zastosowania regresji
Analiza regresji ma liczne zastosowania w różnych dziedzinach:

- **Finanse**: przewidywanie cen akcji lub wskaźników ekonomicznych na podstawie danych historycznych.
- **Nieruchomości**: prognozowanie wartości nieruchomości na podstawie lokalizacji, wielkości i trendów rynkowych.
- **Marketing**: analiza zachowań konsumentów w celu przewidywania wyników sprzedaży na podstawie wydatków na reklamę.

#### Metryki oceny regresji
Aby ocenić wydajność modeli regresji, powszechnie stosuje się kilka metryk:

- **Średni błąd bezwzględny (MAE)**: Mierzy średnią wielkość błędów w przewidywaniach bez uwzględniania ich kierunku.

$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

- **Średni błąd kwadratowy (MSE)**: Mierzy średnią różnicę kwadratową między przewidywanymi a rzeczywistymi wartościami. Większe błędy są przez niego karane bardziej niż MAE.

$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

- **R-kwadrat ($R^2$)**: Wskazuje, jak dobrze zmienne niezależne wyjaśniają zmienność zmiennej zależnej. Wartości mieszczą się w zakresie od 0 do 1, przy czym wyższe wartości oznaczają lepsze dopasowanie modelu.

