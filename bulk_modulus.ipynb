{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# from figrecipes import PlotlyFig\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, HuberRegressor, TheilSenRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from workFiles.functions.coordinator import fit_model, extract_data_to_fit, predicted_properties\n",
    "from workFiles.functions.getDF import get_df\n",
    "from workFiles.functions.helpers import calculate_total_time_left, rmse\n",
    "from workFiles.types import Data_splitted"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = get_df()\n",
    "data = extract_data_to_fit(df, predicted_properties)\n",
    "num_of_features = data.X.shape[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_subsamples = np.linspace(num_of_features + 1, num_of_features * 10, 10, dtype=int)\n",
    "\n",
    "models = [\n",
    "    (LinearRegression, {\n",
    "        \"fit_intercept\": [True],\n",
    "        \"positive\": [True, False]\n",
    "    }),\n",
    "    (Lasso, {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10],\n",
    "        'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'copy_X': [True]\n",
    "    }),\n",
    "    (DecisionTreeRegressor, {\n",
    "        'max_depth': [3, 7, 10, 30, 60, 100, 150, 200],\n",
    "        'min_samples_split': [2, 4, 8, 16, 32],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'splitter': ['best', 'random'],\n",
    "    }),\n",
    "    (Ridge, {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100],\n",
    "        'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'copy_X': [True],\n",
    "        'max_iter': [100_000],\n",
    "        'fit_intercept': [True],\n",
    "    }),\n",
    "    (HuberRegressor, {\n",
    "        'max_iter': [10_000],\n",
    "        'epsilon': [1.0, 1.5, 2.0, 2.5, 3.0],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'fit_intercept': [True],\n",
    "    }),\n",
    "    (SVR, {\n",
    "        'max_iter': [10_000_000],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'degree': [1],\n",
    "        'tol': [1e-04, 1e-03, 1e-02, 1e-01, 1e+00],\n",
    "        'epsilon': [0.0, 0.1, 0.3, 1.0, 3.0, 10.0, 30],\n",
    "    }),\n",
    "    (GradientBoostingRegressor, {\n",
    "        'max_depth': [3, 6, 10, 15, 20],\n",
    "        'n_estimators': [25, 50, 75, 100],\n",
    "        'learning_rate': [0.01, 0.1, 1.0, 10],\n",
    "    }),\n",
    "    (LinearSVR, {\n",
    "        'max_iter': [100_000],\n",
    "        'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'epsilon': [0.0, 0.1, 0.3, 0.6, 1.0, 3.0, 10.0],\n",
    "        'tol': [1e-04, 1e-03, 1e-02, 1e-01, 1e+00],\n",
    "    }),\n",
    "    (TheilSenRegressor, {\n",
    "        'max_iter': [100],\n",
    "        'n_subsamples': n_subsamples,\n",
    "        'fit_intercept': [True],\n",
    "        'tol': [1e-04, 1e-03, 1e-02, 1e-01, 1e+00],\n",
    "    }),\n",
    "    (RandomForestRegressor, {\n",
    "        'n_estimators': [50, 75, 100, 150, 200],\n",
    "        'max_leaf_nodes': [32, 64, 128, 256],\n",
    "        'max_depth': [9, 27, 81],\n",
    "        'bootstrap': [True],\n",
    "    }),\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_already_defined = False",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Results per model and property and grid search parameters\n",
    "if not results_already_defined:\n",
    "    Results = {\n",
    "        column_name: {\n",
    "            model.__name__: {\"instance\": None, \"time_taken\": None} for (model, _) in models\n",
    "        }\n",
    "        for column_name in data.y\n",
    "    }\n",
    "    results_already_defined = True\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, column_name in enumerate(data.y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.X, data.y[column_name], test_size=0.1, random_state=1234\n",
    "    )\n",
    "    data_split = Data_splitted(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print(f\"Property {i}: {column_name}\")\n",
    "    for j, (model, options) in enumerate(models):\n",
    "        if Results[column_name][model.__name__][\"instance\"] is not None:\n",
    "            continue\n",
    "        print(i, j)\n",
    "\n",
    "        model_instance, time_taken = fit_model(model, data_split, column_name, options)\n",
    "\n",
    "        Results[column_name][model.__name__][\"instance\"] = model_instance\n",
    "        Results[column_name][model.__name__][\"time_taken\"] = time_taken\n",
    "\n",
    "        print(f\"Time taken: {time_taken:.2f}[min]\", end=\"\\n\\n\")\n",
    "        print(f\"Estimated Time Left: {calculate_total_time_left(Results):.2f}[min]\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": " Results",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_time = 0\n",
    "for el in Results:\n",
    "    for model in Results[el]:\n",
    "        time_taken = Results[el][model]['time_taken']\n",
    "        total_time += time_taken or 0\n",
    "\n",
    "print(f'{round(total_time, 1)}[min]')\n",
    "print(f'{round(total_time / 60, 1)}[h]')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for feature in Results:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.X, data.y[feature], test_size=0.1, random_state=1234\n",
    "    )\n",
    "    print()\n",
    "    print(feature)\n",
    "    print()\n",
    "    for model in Results[feature]:\n",
    "        fitted_model = Results[feature][model]['instance']\n",
    "\n",
    "        r2_test = round(fitted_model.best_estimator_.score(X_test, y_test), 3)\n",
    "        rmse_test = round(rmse(y_test, fitted_model.best_estimator_.predict(X_test)), 3)\n",
    "\n",
    "        print(f'{model=}')\n",
    "        print(f'R2: {r2_test}', end=\", \")\n",
    "        print(f\"Time: {Results[feature][model]['time_taken']:.2f}[min]\", rmse_test, sep=\",\\t\")\n",
    "        print(f\"Best params: {fitted_model.best_params_}\", end=\"\\n\\n\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(Results, 'workFiles/bulk_modulus_results.joblib')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
